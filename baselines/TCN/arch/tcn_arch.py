import torch
from torch import nn
import torch.nn.functional as F


class Chomp1d(nn.Module):
    """ç§»é™¤paddingäº§ç”Ÿçš„æœªæ¥ä¿¡æ¯ï¼Œç¡®ä¿å› æœæ€§"""

    def __init__(self, chomp_size):
        super(Chomp1d, self).__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        if self.chomp_size == 0:
            return x
        return x[:, :, :-self.chomp_size].contiguous()


class TCNBlock(nn.Module):
    """TCNåŸºæœ¬å—ï¼ŒåŒ…å«æ®‹å·®è¿æ¥ - ç§»é™¤weight_normæé«˜ç¨³å®šæ€§"""

    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.2):
        super(TCNBlock, self).__init__()

        # è®¡ç®—paddingä»¥ä¿æŒåºåˆ—é•¿åº¦
        padding = (kernel_size - 1) * dilation

        # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ - ç§»é™¤weight_norm
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,
                               padding=padding, dilation=dilation)
        self.chomp1 = Chomp1d(padding)
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)

        # ç¬¬äºŒä¸ªå·ç§¯å±‚ - ç§»é™¤weight_norm
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,
                               padding=padding, dilation=dilation)
        self.chomp2 = Chomp1d(padding)
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(dropout)

        # ç»„åˆç½‘ç»œ
        self.net = nn.Sequential(
            self.conv1, self.chomp1, self.relu1, self.dropout1,
            self.conv2, self.chomp2, self.relu2, self.dropout2
        )

        # æ®‹å·®è¿æ¥çš„ç»´åº¦åŒ¹é…
        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None
        self.relu = nn.ReLU()

        self.init_weights()

    def init_weights(self):
        """åˆå§‹åŒ–æƒé‡ - ä½¿ç”¨æ›´ç¨³å®šçš„åˆå§‹åŒ–"""
        # ä½¿ç”¨Xavier/Glorotåˆå§‹åŒ–
        nn.init.xavier_uniform_(self.conv1.weight)
        nn.init.xavier_uniform_(self.conv2.weight)
        nn.init.zeros_(self.conv1.bias)
        nn.init.zeros_(self.conv2.bias)

        if self.downsample is not None:
            nn.init.xavier_uniform_(self.downsample.weight)
            nn.init.zeros_(self.downsample.bias)

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        out = self.net(x)
        res = x if self.downsample is None else self.downsample(x)
        return self.relu(out + res)


class TCN(nn.Module):
    """ç¨³å®šçš„TCNæ¨¡å‹"""

    def __init__(self, num_layers, in_dim, hidden_dim, output_dim, kernel_size=3, dropout=0.2):
        super(TCN, self).__init__()

        self.num_layers = num_layers
        self.in_dim = in_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.kernel_size = kernel_size
        self.dropout_p = dropout

        # è¾“å…¥ç¼–ç å±‚
        self.encoder = nn.Conv1d(in_dim, hidden_dim, kernel_size=1)
        nn.init.xavier_uniform_(self.encoder.weight)
        nn.init.zeros_(self.encoder.bias)

        # TCNå±‚
        self.tcn_layers = nn.ModuleList()
        for i in range(num_layers):
            dilation = 2 ** i
            tcn_block = TCNBlock(
                in_channels=hidden_dim,
                out_channels=hidden_dim,
                kernel_size=kernel_size,
                dilation=dilation,
                dropout=dropout
            )
            self.tcn_layers.append(tcn_block)

        # è¾“å‡ºæŠ•å½±å±‚
        self.proj = nn.Conv1d(hidden_dim, output_dim, kernel_size=1)
        nn.init.xavier_uniform_(self.proj.weight)
        nn.init.zeros_(self.proj.bias)

    def forward(self, history_data: torch.Tensor, future_data: torch.Tensor = None,
                batch_seen: int = None, epoch: int = None, train: bool = True,
                **kwargs) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­

        Args:
            history_data (torch.Tensor): è¾“å…¥æ•°æ®ï¼Œshape [B, L, N, C]

        Returns:
            torch.Tensor: è¾“å‡ºæ•°æ®ï¼Œshape [B, L, N, output_dim]
        """
        # è¾“å…¥éªŒè¯
        if torch.isnan(history_data).any() or torch.isinf(history_data).any():
            print("Warning: Input contains NaN or Inf values!")
            history_data = torch.nan_to_num(history_data, nan=0.0, posinf=1e6, neginf=-1e6)

        B, T, N, D = history_data.shape

        # é‡å¡‘ä¸ºå·ç§¯æœŸæœ›çš„æ ¼å¼: (B*N, D, T)
        x = history_data.permute(0, 2, 3, 1).contiguous()  # [B, N, D, T]
        x = x.view(B * N, D, T)  # [B*N, D, T]

        # ç‰¹å¾ç¼–ç 
        x = self.encoder(x)  # (B*N, hidden_dim, T)

        # æ£€æŸ¥ç¼–ç åæ˜¯å¦æœ‰å¼‚å¸¸å€¼
        if torch.isnan(x).any() or torch.isinf(x).any():
            print("Warning: Encoder output contains NaN or Inf!")
            x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)

        # é€šè¿‡TCNå±‚
        for i, tcn_block in enumerate(self.tcn_layers):
            x_before = x
            x = tcn_block(x)

            # æ£€æŸ¥æ¯å±‚è¾“å‡º
            if torch.isnan(x).any() or torch.isinf(x).any():
                print(f"Warning: TCN layer {i} output contains NaN or Inf!")
                x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)

            # æ£€æŸ¥æ˜¯å¦å…¨ä¸º0
            if torch.all(x == 0):
                print(f"Warning: TCN layer {i} output is all zeros!")
                x = x_before * 0.1  # ä½¿ç”¨å‰ä¸€å±‚çš„ç¼©å°ç‰ˆæœ¬

        # è¾“å‡ºæŠ•å½±
        x = self.proj(x)  # (B*N, output_dim, T)

        # æœ€ç»ˆæ£€æŸ¥
        if torch.isnan(x).any() or torch.isinf(x).any():
            print("Warning: Final output contains NaN or Inf!")
            x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)

        # ğŸ”¥ ä¿®æ­£ç»´åº¦é‡å¡‘é”™è¯¯
        x = x.permute(0, 2, 1)  # (B*N, T, output_dim)
        x = x.view(B, N, T, self.output_dim)  # æ­£ç¡®çš„viewæ“ä½œ
        x = x.permute(0, 2, 1, 3)  # (B, T, N, output_dim)

        return x


class StableTrainingTCN(nn.Module):
    """é¢å¤–ç¨³å®šæ€§æ”¹è¿›çš„TCNç‰ˆæœ¬"""

    def __init__(self, num_layers, in_dim, hidden_dim, output_dim, kernel_size=3, dropout=0.1):
        super(StableTrainingTCN, self).__init__()

        self.num_layers = num_layers
        self.in_dim = in_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim

        # é™ä½dropoutç‡æé«˜ç¨³å®šæ€§
        self.dropout_p = min(dropout, 0.1)

        # è¾“å…¥å½’ä¸€åŒ–
        self.input_norm = nn.LayerNorm(in_dim)

        # ç‰¹å¾ç¼–ç 
        self.encoder = nn.Sequential(
            nn.Conv1d(in_dim, hidden_dim, kernel_size=1),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU()
        )

        # TCNå±‚ - ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
        self.tcn_layers = nn.ModuleList()
        for i in range(num_layers):
            dilation = 2 ** i
            layer = nn.Sequential(
                nn.Conv1d(hidden_dim, hidden_dim, kernel_size,
                          padding=(kernel_size - 1) * dilation, dilation=dilation),
                Chomp1d((kernel_size - 1) * dilation),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(self.dropout_p)
            )
            self.tcn_layers.append(layer)

        # è¾“å‡ºå±‚
        self.output_layer = nn.Sequential(
            nn.Conv1d(hidden_dim, hidden_dim // 2, kernel_size=1),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(self.dropout_p),
            nn.Conv1d(hidden_dim // 2, output_dim, kernel_size=1)
        )

        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)

    def _init_weights(self, module):
        """ç¨³å®šçš„æƒé‡åˆå§‹åŒ–"""
        if isinstance(module, nn.Conv1d):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
            if module.bias is not None:
                nn.init.zeros_(module.bias)
        elif isinstance(module, nn.BatchNorm1d):
            nn.init.ones_(module.weight)
            nn.init.zeros_(module.bias)

    def forward(self, history_data: torch.Tensor, **kwargs) -> torch.Tensor:
        """ç¨³å®šçš„å‰å‘ä¼ æ’­"""
        B, T, N, D = history_data.shape

        # è¾“å…¥å½’ä¸€åŒ–
        x = self.input_norm(history_data)

        # é‡å¡‘ç»´åº¦
        x = x.permute(0, 2, 3, 1).contiguous().view(B * N, D, T)

        # ç¼–ç 
        x = self.encoder(x)

        # TCNå¤„ç†
        for layer in self.tcn_layers:
            residual = x
            x = layer(x)
            # æ®‹å·®è¿æ¥
            x = x + residual
            # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            x = torch.clamp(x, -10, 10)

        # è¾“å‡º
        x = self.output_layer(x)

        # é‡å¡‘å›åŸå§‹æ ¼å¼
        x = x.permute(0, 2, 1).contiguous()  # (B*N, T, output_dim)
        x = x.view(B, N, T, self.output_dim).permute(0, 2, 1, 3)

        return x

